# appLAB.py
import streamlit as st
import pandas as pd
import plotly.express as px
import re
from sqlalchemy import create_engine, text
from login_interface import show_login_page, show_logout_button
from db_utils import introspect_schema
from openai import OpenAI
import pandasql as ps

st.set_page_config(page_title="Plataforma de Dados", layout="wide")


# ----------------------
# Utilit√°rios e Fun√ß√µes da IA
# ----------------------

def build_history_text(history, max_turns=6):
    """Converte hist√≥rico em texto compacto para enviar √† IA."""
    if not history: return ""
    max_messages = max_turns * 2;
    recent = history[-max_messages:]
    lines = [f"{'Usu√°rio' if msg['role'] == 'user' else 'Assistente'}: {msg['content'].replace('```', ' `` ')}" for msg
             in recent]
    return "\n".join(lines)


def extract_sql(text: str) -> str:
    """Extrai SQL de um texto."""
    if not text: return ""
    m = re.search(r"```(?:sql)?\s*(.*?)```", text, re.S | re.I)
    if m: return m.group(1).strip()
    m2 = re.search(r"(?i)(\bselect\b|\bwith\b|\binsert\b|\bupdate\b|\bdelete\b)(.*)", text, re.S)
    if m2: return (m2.group(1) + m2.group(2)).strip()
    return text.strip()


def describe_dataframe_schema(df: pd.DataFrame) -> str:
    """Retorna esquema textual de um DataFrame."""
    lines = [f"A tabela se chama 'df' e possui as seguintes colunas:"]
    for col in df.columns: lines.append(f'- "{col}" (tipo: {str(df[col].dtype)})')
    return "\n".join(lines)


# --- FUN√á√ïES DE IA ESPECIALIZADAS ---

def generate_sql(client, model_name, system_prompt, schema_text, history_text, question):
    """Fun√ß√£o gen√©rica para pedir SQL √† OpenAI, retornando SQL ou NO_SQL."""
    messages = [
        {"role": "system", "content": system_prompt + "\n\n---\nEsquema dos Dados:\n" + schema_text},
        {"role": "user",
         "content": f"Hist√≥rico:\n{history_text or '(sem hist√≥rico)'}\n\nPergunta:\n{question}\n\nINSTRU√á√ïES:\n- Retorne apenas a SQL.\n- Se n√£o precisar de SQL, retorne: NO_SQL"},
    ]
    resp = client.chat.completions.create(model=model_name, messages=messages, temperature=0.0, max_tokens=800)
    return resp.choices[0].message.content.strip()


def generate_humanized_answer(client, model_name, question, df_result, sql_text=None, show_sql=False):
    """Gera resposta humanizada. Inclui SQL apenas se show_sql=True."""
    preview_text = df_result.head(10).to_markdown(
        index=False) if df_result is not None and not df_result.empty else "(A consulta n√£o retornou dados)"
    system_prompt = (
        "Voc√™ √© um assistente de BI que explica resultados de forma clara e amig√°vel para um usu√°rio de neg√≥cios.\n"
        "Sua resposta DEVE ser estruturada e informativa. Use t√≥picos, negrito e tabelas em markdown."
    )
    user_content = f"Com base na pergunta '{question}' e nos dados retornados, gere uma an√°lise completa e informativa.\n\nPreview dos Dados:\n{preview_text}\n\n"
    if show_sql and sql_text:
        system_prompt += "\nSua resposta DEVE terminar com a consulta SQL utilizada."
        user_content += f"Consulta SQL Executada:\n```sql\n{sql_text}\n```"
    else:
        system_prompt += "\nNUNCA inclua o c√≥digo SQL na sua resposta."
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}]
    resp = client.chat.completions.create(model=model_name, messages=messages, temperature=0.2, max_tokens=1000)
    return resp.choices[0].message.content.strip()


def generate_suggestions(client, model_name, schema_text, question):
    """Gera sugest√µes de an√°lise quando uma consulta SQL n√£o √© apropriada."""
    system_prompt = (
        "Voc√™ √© um analista de dados s√™nior e proativo. Seu objetivo √© ajudar o usu√°rio a descobrir insights em seus dados.\n"
        "O usu√°rio fez uma pergunta que n√£o resultou em uma consulta direta. Com base no esquema dos dados, sugira de 3 a 5 perguntas ou tipos de gr√°ficos interessantes que ele poderia fazer para explorar melhor seus dados.\n"
        "Apresente as sugest√µes em formato de lista (t√≥picos)."
    )
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user",
         "content": f"A minha pergunta foi: '{question}'.\n\nO esquema dos dados dispon√≠veis √©:\n{schema_text}\n\nCom base nisso, quais an√°lises voc√™ me sugere?"}
    ]
    resp = client.chat.completions.create(model=model_name, messages=messages, temperature=0.5, max_tokens=500)
    return resp.choices[0].message.content.strip()


# --- FUN√á√ïES DO DASHBOARD E UTILIT√ÅRIOS GERAIS ---

def generate_chart_instructions(client, model_name, schema_text, question, df_preview=None):
    """Pede instru√ß√µes de gr√°fico para a IA."""
    preview_text = df_preview.head(5).to_markdown(
        index=False) if df_preview is not None and not df_preview.empty else ""
    system_content = (
        "Voc√™ √© um assistente que cria dashboards gerando uma consulta SQL e sua configura√ß√£o.\n"
        "REGRAS CR√çTICAS:\n"
        "1. Use EXCLUSIVAMENTE os nomes de colunas fornecidos no esquema.\n"
        "2. Se um nome de coluna contiver espa√ßos ou caracteres especiais, voc√™ DEVE envolv√™-lo em aspas duplas (ex: `\"Receita Total (R$)\"`).\n"
        "3. A consulta deve ser compat√≠vel com o dialeto SQLite (usado por pandasql).\n"
        "4. Retorne a resposta APENAS no formato especificado abaixo, sem nenhuma outra explica√ß√£o.\n"
        "\n--- FORMATO OBRIGAT√ìRIO ---\n"
        "SQL: <query>\n"
        "Tipo: <bar|line|pie>\n"
        "X: <coluna para o eixo X>\n"
        "Y: <coluna para o eixo Y>\n"
        "T√≠tulo: <t√≠tulo para o gr√°fico>"
    )
    messages = [{"role": "system", "content": system_content}, {"role": "user",
                                                                "content": f"Esquema:\n{schema_text}\n\nPreview dos Dados:\n{preview_text}\n\nPedido do Usu√°rio:\n{question}"}]
    resp = client.chat.completions.create(model=model_name, messages=messages, temperature=0.0, max_tokens=500)
    return resp.choices[0].message.content.strip()


def parse_chart_instructions(text):
    """Extrai SQL, tipo, eixos e t√≠tulo da resposta da IA."""
    chart = {"sql": None, "type": "bar", "x": None, "y": None, "title": "Gr√°fico"}
    for line in text.splitlines():
        if line.strip().lower().startswith("sql:"):
            chart["sql"] = line.split(":", 1)[1].strip()
        elif line.strip().lower().startswith("tipo:"):
            chart["type"] = line.split(":", 1)[1].strip().lower()
        elif line.strip().lower().startswith("x:"):
            chart["x"] = line.split(":", 1)[1].strip()
        elif line.strip().lower().startswith("y:"):
            chart["y"] = line.split(":", 1)[1].strip()
        elif line.strip().lower().startswith("t√≠tulo:") or line.strip().lower().startswith("titulo:"):
            chart["title"] = line.split(":", 1)[1].strip()
    return chart


def _strip_quotes(val: str):
    """Remove aspas extras de nomes de colunas."""
    if not isinstance(val, str): return val
    return val.strip().strip('"').strip("'")


def render_chart(chart_config):
    """Renderiza gr√°fico Plotly."""
    df = chart_config.get("df", pd.DataFrame())
    if df is None or df.empty:
        st.warning("Sem dados para exibir neste gr√°fico.")
        return
    tipo = chart_config.get("type", "bar")
    x = _strip_quotes(chart_config.get("x")) if chart_config.get("x") else None
    y = _strip_quotes(chart_config.get("y")) if chart_config.get("y") else None
    if x and x not in df.columns: st.error(f"Eixo X inv√°lido '{x}'. Colunas: {list(df.columns)}"); return
    if y and y not in df.columns and tipo != "pie": st.error(
        f"Eixo Y inv√°lido '{y}'. Colunas: {list(df.columns)}"); return
    try:
        if tipo == "bar":
            fig = px.bar(df, x=x, y=y, title=chart_config.get("title", "Gr√°fico"))
        elif tipo == "line":
            fig = px.line(df, x=x, y=y, title=chart_config.get("title", "Gr√°fico"))
        elif tipo == "pie":
            fig = px.pie(df, names=x, values=y, title=chart_config.get("title", "Gr√°fico"))
        else:
            st.warning(f"Tipo de gr√°fico '{tipo}' n√£o suportado."); return
        st.plotly_chart(fig, use_container_width=True)
    except Exception as e:
        st.error(f"Erro ao gerar gr√°fico: {e}")


def validate_sql_tables(sql_text, db_mode, schema_dict=None):
    """Valida se as tabelas da SQL existem."""
    if not sql_text: return False, "Consulta SQL vazia."
    sql_lower = sql_text.lower()
    if db_mode:
        if not schema_dict: return True, None
        available = list(schema_dict.keys())
        found = any(re.search(r"\b" + re.escape(t.lower()) + r"\b", sql_lower) for t in available)
        if not found: return False, f"Tabela n√£o encontrada na consulta. Dispon√≠veis: {', '.join(available)}"
        return True, None
    else:
        if re.search(r"\bfrom\s+df\b", sql_lower) or re.search(r"\bfrom\s+\"df\"\b", sql_lower): return True, None
        return False, "Para CSV/Excel use a tabela chamada 'df'."


# ----------------------
# App principal
# ----------------------
if 'logged_in' not in st.session_state:
    st.session_state['logged_in'] = False

if not st.session_state['logged_in']:
    show_login_page()
else:
    st.title("An√°lise Inteligente de Dados üöÄ")
    show_logout_button()

    with st.sidebar:
        st.header("üîë Configura√ß√µes")
        openai_api_key = st.text_input("Chave OpenAI", type="password")
        modelo_selecionado = st.selectbox("Modelo:", ("gpt-4o-mini", "gpt-4o", "gpt-3.5-turbo", "gpt-4"))
        st.subheader("üìÇ Fonte de Dados")
        fonte_dados = st.selectbox("Fonte:", ["Banco de Dados", "Arquivo CSV/Excel"])
        db_user = db_password = db_host = db_port = db_name = None
        uploaded_file = None
        if fonte_dados == "Banco de Dados":
            db_user = st.text_input("Usu√°rio", "user");
            db_password = st.text_input("Senha", "password", type="password")
            db_host = st.text_input("Host", "localhost");
            db_port = st.text_input("Porta", "5432");
            db_name = st.text_input("Banco", "meubanco")
        else:
            uploaded_file = st.file_uploader("Upload CSV/Excel", type=["csv", "xlsx"])

    tab1, tab2, tab3 = st.tabs(["üí¨ Conversa", "üìä Dashboard", "üìù Hist√≥rico"])

    with tab1:
        st.header("Converse com seus Dados")
        if not openai_api_key:
            st.warning("Insira a chave da API OpenAI para come√ßar.")
        else:
            client = OpenAI(api_key=openai_api_key)
            db_mode = (fonte_dados == "Banco de Dados")
            schema_text = "(sem esquema)";
            df_data = None;
            uri = None

            try:
                if db_mode:
                    uri = f"postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}"
                    if st.session_state.get('connected_uri') != uri:
                        with st.spinner("Analisando esquema do banco de dados..."):
                            schema_text, schema_dict = introspect_schema(uri)
                            st.session_state['schema_text'] = schema_text;
                            st.session_state['schema_dict'] = schema_dict;
                            st.session_state['connected_uri'] = uri
                    schema_text = st.session_state.get('schema_text', "(sem esquema)")
                else:
                    if uploaded_file is not None:
                        df_data = pd.read_csv(uploaded_file) if uploaded_file.name.endswith(".csv") else pd.read_excel(
                            uploaded_file)
                        st.session_state['df_data'] = df_data;
                        schema_text = describe_dataframe_schema(df_data)
                    elif 'df_data' in st.session_state:
                        df_data = st.session_state['df_data'];
                        schema_text = describe_dataframe_schema(df_data)
                    else:
                        st.info("Fa√ßa upload de um arquivo CSV ou Excel para come√ßar a an√°lise.")
            except Exception as e:
                st.error(f"Falha ao carregar a fonte de dados: {e}")

            if 'history' not in st.session_state: st.session_state.history = []
            for message in st.session_state.history:
                with st.chat_message(message["role"]): st.markdown(message["content"])

            if prompt := st.chat_input("Pergunte algo sobre seus dados..."):
                st.session_state.history.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                with st.chat_message("assistant"):
                    with st.spinner("Analisando..."):
                        if (db_mode and schema_text == "(sem esquema)") or (not db_mode and df_data is None):
                            st.warning(
                                "Fonte de dados n√£o est√° pronta. Conecte ao banco ou fa√ßa upload de um arquivo.");
                            st.stop()

                        history_text = build_history_text(st.session_state.history, max_turns=6)

                        if db_mode:
                            system_prompt = "Voc√™ √© um especialista em PostgreSQL. Gere SQL para responder a perguntas sobre o esquema fornecido."
                        else:
                            system_prompt = (
                                "Voc√™ √© um especialista em pandasql que gera c√≥digo SQL para consultar um DataFrame chamado 'df'.\n"
                                "INSTRU√á√ïES CR√çTICAS:\n"
                                "1. Use EXCLUSIVAMENTE os nomes de colunas fornecidos no esquema. N√ÉO INVENTE nomes de colunas.\n"
                                "2. A tabela a ser consultada √© SEMPRE chamada de 'df'.\n"
                                "3. Se um nome de coluna contiver espa√ßos ou caracteres especiais, voc√™ DEVE envolv√™-lo em aspas duplas (ex: `\"Nome Completo\"`).\n"
                                "4. Se a pergunta do usu√°rio for amb√≠gua ou claramente n√£o pedir por dados (ex: 'ol√°', 'me d√™ sugest√µes'), retorne 'NO_SQL'."
                            )

                        sql_candidate = generate_sql(client, modelo_selecionado, system_prompt, schema_text,
                                                     history_text, prompt)

                        if sql_candidate.strip().upper() == "NO_SQL":
                            final_text = generate_suggestions(client, modelo_selecionado, schema_text, prompt)
                            st.markdown(final_text)
                            st.session_state.history.append({"role": "assistant", "content": final_text})
                        else:
                            sql_text = extract_sql(sql_candidate)
                            schema_dict = st.session_state.get('schema_dict', {})
                            ok, vmsg = validate_sql_tables(sql_text, db_mode, schema_dict)

                            if not ok:
                                final_text = f"Erro de valida√ß√£o: {vmsg}"
                                st.markdown(final_text)
                                st.session_state.history.append({"role": "assistant", "content": final_text})
                            else:
                                try:
                                    if db_mode:
                                        engine = create_engine(uri)
                                        with engine.connect() as conn:
                                            df_result = pd.read_sql(text(sql_text), conn)
                                    else:
                                        df_result = ps.sqldf(sql_text, {"df": df_data})

                                    final_text = generate_humanized_answer(client, modelo_selecionado, prompt,
                                                                           df_result, sql_text, show_sql=db_mode)

                                    st.markdown(final_text)
                                    if not df_result.empty:
                                        st.subheader("Preview dos dados retornados")
                                        st.dataframe(df_result.head(100))
                                    st.session_state.history.append({"role": "assistant", "content": final_text})

                                except Exception as e:
                                    error_message = f"Ocorreu um erro ao executar a an√°lise: {e}"
                                    st.error(error_message)
                                    st.session_state.history.append({"role": "assistant", "content": error_message})

    with tab2:
        st.header("Dashboard Interativo üìä")
        if 'charts' not in st.session_state: st.session_state.charts = []

        db_mode_dash = (fonte_dados == "Banco de Dados")
        schema_text_ctx = st.session_state.get(
            'schema_text') if db_mode_dash and 'schema_text' in st.session_state else describe_dataframe_schema(
            st.session_state.get('df_data', pd.DataFrame()))
        schema_dict_ctx = st.session_state.get('schema_dict') if db_mode_dash else None
        df_data_ctx = st.session_state.get('df_data') if not db_mode_dash else None
        uri_ctx = f"postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}" if db_mode_dash else None

        for idx, chart in enumerate(st.session_state.charts):
            st.subheader(chart.get("title", f"Gr√°fico {idx + 1}"))
            render_chart(chart)

            with st.expander(f"Op√ß√µes para Gr√°fico {idx + 1}"):
                edit_prompt = st.text_input("Refine ou altere este gr√°fico:", key=f"edit_{idx}")

                col1, col2 = st.columns(2)
                with col1:
                    if st.button("Atualizar Gr√°fico", key=f"update_{idx}"):
                        if edit_prompt.strip() and openai_api_key:
                            with st.spinner("Atualizando gr√°fico..."):
                                try:
                                    client = OpenAI(api_key=openai_api_key)
                                    instr_text = generate_chart_instructions(client, modelo_selecionado,
                                                                             schema_text_ctx, edit_prompt, df_data_ctx)
                                    new_chart_cfg = parse_chart_instructions(instr_text)
                                    valid, msg = validate_sql_tables(new_chart_cfg["sql"], db_mode_dash,
                                                                     schema_dict_ctx)
                                    if not valid:
                                        st.error(msg)
                                    else:
                                        if db_mode_dash and uri_ctx:
                                            engine = create_engine(uri_ctx);
                                            df_result = pd.read_sql(text(new_chart_cfg["sql"]), engine)
                                        elif not db_mode_dash and df_data_ctx is not None:
                                            df_result = ps.sqldf(new_chart_cfg["sql"], {"df": df_data_ctx})
                                        else:
                                            df_result = pd.DataFrame()

                                        if not df_result.empty:
                                            new_chart_cfg["df"] = df_result
                                            st.session_state.charts[idx] = new_chart_cfg
                                            st.rerun()
                                        else:
                                            st.warning("A nova consulta para o gr√°fico n√£o retornou dados.")
                                except Exception as e:
                                    st.error(f"Erro ao atualizar gr√°fico: {e}")

                with col2:
                    if st.button("Remover Gr√°fico", type="primary", key=f"remove_{idx}"):
                        st.session_state.charts.pop(idx)
                        st.rerun()

        st.subheader("Adicionar novo gr√°fico")
        new_chart_prompt = st.text_input("Descreva o gr√°fico que voc√™ deseja criar:", key="new_chart_prompt_input")
        if st.button("Gerar novo gr√°fico", key="new_chart_btn"):  # <<< CORRE√á√ÉO APLICADA AQUI
            if new_chart_prompt.strip() and openai_api_key:
                with st.spinner("Gerando gr√°fico..."):
                    try:
                        client = OpenAI(api_key=openai_api_key)
                        instr_text = generate_chart_instructions(client, modelo_selecionado, schema_text_ctx,
                                                                 new_chart_prompt, df_data_ctx)
                        chart_cfg = parse_chart_instructions(instr_text)
                        valid, msg = validate_sql_tables(chart_cfg["sql"], db_mode_dash, schema_dict_ctx)
                        if not valid:
                            st.error(msg)
                        else:
                            if db_mode_dash and uri_ctx:
                                engine = create_engine(uri_ctx);
                                df_result = pd.read_sql(text(chart_cfg["sql"]), engine)
                            elif not db_mode_dash and df_data_ctx is not None:
                                df_result = ps.sqldf(chart_cfg["sql"], {"df": df_data_ctx})
                            else:
                                st.warning("Fonte de dados n√£o est√° pronta.");
                                df_result = pd.DataFrame()
                            if not df_result.empty:
                                chart_cfg["df"] = df_result;
                                st.session_state.charts.append(chart_cfg);
                                st.rerun()
                            else:
                                st.warning("A consulta para o gr√°fico n√£o retornou dados.")
                    except Exception as e:
                        st.error(f"Erro ao adicionar gr√°fico: {e}")

    with tab3:
        st.header("Hist√≥rico de Conversas üìù")
        if 'history' not in st.session_state or not st.session_state.history:
            st.info("Nenhuma conversa registrada ainda.")
        else:
            for i, msg in enumerate(st.session_state.history):
                role = "üë§ Usu√°rio" if msg["role"] == "user" else "ü§ñ Assistente"
                with st.expander(f"{role} - Mensagem {i + 1}"): st.markdown(msg["content"])
            if st.button("üóëÔ∏è Limpar Hist√≥rico"):
                st.session_state.history = [];
                st.rerun()